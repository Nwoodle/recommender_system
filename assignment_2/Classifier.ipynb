{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Attempt to apply a classifier into the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "c:\\Users\\Renjie Zhu\\Documents\\workspace\\recommender_system\\assignment_2\n"
    }
   ],
   "source": [
    "import os\n",
    "try:\n",
    "\tos.chdir(os.path.join(os.getcwd(), 'assignment_2'))\n",
    "\tprint(os.getcwd())\n",
    "except:\n",
    "\tpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "def train_test_validation(closed_data, train_frac=0.8):\n",
    "    \"\"\" 8:1:1 train, text ,validation split \"\"\"\n",
    "    train = closed_data.sample(frac=train_frac)\n",
    "    remain = closed_data.drop(train.index)\n",
    "    test = remain.sample(frac=0.5)\n",
    "    validation = remain.drop(test.index)\n",
    "    return train, test, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Dataset size is 125177.\n"
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "closed_data = pd.read_csv(\"closed_data.csv\")\n",
    "closed_data = closed_data.loc[closed_data[\"district\"].isin([1,2,3,4,5,6,7,8,9])]\n",
    "print(f\"Dataset size is {len(closed_data)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns\n",
    "'''\n",
    "Preprocessing:\n",
    "\t- Keep only closed case\n",
    "\t- Keep case with district data\n",
    "\n",
    "Features:\n",
    "\t- Service name: service_name, onehot\n",
    "\t- Total population: total_pop2017\n",
    "\t- White population: white_pop2017\n",
    "\t- African American population: afram_pop2017\n",
    "\t- Hispanic population population: hisp_pop2017\n",
    "\t- Case origion: case_origin, onehot\n",
    "\t- Description sentiment: feature sentiment analysis, homebrewed\n",
    "        - neg, neu, com, pos\n",
    "    - Average income: avg_agi\n",
    "'''\n",
    "column_lst = [\"total_pop2017\", \"white_pop2017\", \"afram_pop2017\", \"hisp_pop2017\",\\\n",
    "              \"avg_agi\", \"neg\", \"neu\", \"com\", \"pos\"]\n",
    "onehot_lst = [\"service_name\", \"case_origin\"]\n",
    "prep_data = closed_data[column_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Onehot Process\n",
    "onehot_data = closed_data[onehot_lst]\n",
    "categorize_data = pd.get_dummies(onehot_data, prefix=onehot_lst)\n",
    "logistic_label = closed_data[\"lncase_age_days\"] <= 1.0\n",
    "dataset = pd.concat([prep_data, categorize_data], axis=1)\n",
    "dataset[\"logis_label\"] = logistic_label.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "count    125177.000000\nmean          0.230026\nstd           0.420851\nmin           0.000000\n25%           0.000000\n50%           0.000000\n75%           0.000000\nmax           1.000000\nName: logis_label, dtype: float64"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"logis_label\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, validation = train_test_validation(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## naive logistic regression (log(casetime)<1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}