{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "c:\\Users\\Renjie Zhu\\Documents\\workspace\\recommender_system\\assignment_2\n"
    }
   ],
   "source": [
    "# ms-python.python added\n",
    "import os\n",
    "try:\n",
    "\tos.chdir(os.path.join(os.getcwd(), 'assignment_2'))\n",
    "\tprint(os.getcwd())\n",
    "except:\n",
    "\tpass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "[nltk_data] Downloading package vader_lexicon to C:\\Users\\Renjie\n[nltk_data]     Zhu\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n"
    }
   ],
   "source": [
    "from preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data_preprocessing(threshold=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, valid = train_test_validation(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_model.LogisticRegression(C=0.005, class_weight=\"balanced\")\n",
    "svmodel = svm.LinearSVC(C=0.0001, class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_label = data_label(train)\n",
    "valid_data, valid_label = data_label(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "C:\\Users\\Renjie Zhu\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\nC:\\Users\\Renjie Zhu\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n"
    },
    {
     "data": {
      "text/plain": "LogisticRegression(C=0.005, class_weight='balanced', dual=False,\n                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n                   warm_start=False)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, train_label)\n",
    "# svmodel.fit(train_data, train_label)\n",
    "# linear.fit(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.7317443813484764"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(valid_data, valid_label)\n",
    "# linear.score(valid_data, valid_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.7321408932302862"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(train_data, train_label)\n",
    "# linear.score(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "for l = 3, Valid_Accuracy = 0.7465408302007518\nfor l = 3, Train_Accuracy = 0.7501474719803237\nfor l = 4, Valid_Accuracy = 0.7480604654882829\nfor l = 4, Train_Accuracy = 0.7527569761745269\nfor l = 5, Valid_Accuracy = 0.7484603695113173\nfor l = 5, Train_Accuracy = 0.7559463701896639\nfor l = 6, Valid_Accuracy = 0.7512596976725586\nfor l = 6, Train_Accuracy = 0.7581959427708735\nfor l = 7, Valid_Accuracy = 0.7481404462928897\nfor l = 7, Train_Accuracy = 0.7632849758545877\nfor l = 8, Valid_Accuracy = 0.7491002159481724\nfor l = 8, Train_Accuracy = 0.7664943660704466\nfor l = 9, Valid_Accuracy = 0.7474206190514276\nfor l = 9, Train_Accuracy = 0.7727931692978334\n"
    }
   ],
   "source": [
    "D_train = xgb.DMatrix(train_data, label=train_label)\n",
    "D_valid = xgb.DMatrix(valid_data, label=valid_label)\n",
    "\n",
    "\n",
    "# best\n",
    "for l in [3,4,5,6,7,8,9]:\n",
    "    param = {\n",
    "        'eta': 0.3, \n",
    "        'max_depth': l,  \n",
    "        'objective': 'multi:softprob',  \n",
    "        'num_class': 2\n",
    "    } \n",
    "\n",
    "    steps = 100  # The number of training iterations\n",
    "    model = xgb.train(param, D_train, steps)\n",
    "\n",
    "    preds = model.predict(D_valid)\n",
    "    best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "\n",
    "    # print(\"Precision = {}\".format(precision_score(valid_label, best_preds, average='macro')))\n",
    "    # print(\"Recall = {}\".format(recall_score(valid_label, best_preds, average='macro')))\n",
    "    print(f\"for l = {l}, Valid_Accuracy = {accuracy_score(valid_label, best_preds)}\")\n",
    "\n",
    "    preds = model.predict(D_train)\n",
    "    best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "\n",
    "    # print(\"Precision = {}\".format(precision_score(train_label, best_preds, average='macro')))\n",
    "    # print(\"Recall = {}\".format(recall_score(train_label, best_preds, average='macro')))\n",
    "    print(f\"for l = {l}, Train_Accuracy = {accuracy_score(train_label, best_preds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Accuracy = 0.7480604654882829\n"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Accuracy = 0.7557164138813626\n"
    }
   ],
   "source": [
    "preds = model.predict(D_train)\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "\n",
    "# print(\"Precision = {}\".format(precision_score(train_label, best_preds, average='macro')))\n",
    "# print(\"Recall = {}\".format(recall_score(train_label, best_preds, average='macro')))\n",
    "print(\"Accuracy = {}\".format(accuracy_score(train_label, best_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}